[
  {
    "path": "index.html",
    "id": "webexercises",
    "chapter": "Webexercises",
    "heading": "Webexercises",
    "text": "Web Exercise template created #PsyTeachR team University Glasgow, based ideas Software Carpentry. template shows instructors can easily create interactive web documents students can use self-guided learning.webexercises package provides number functions use inline R code code chunk options create HTML widgets (text boxes, pull menus, buttons reveal hidden content). Examples given next. Render book see work.NOTE: use widgets compiled HTML files, need JavaScript-enabled browser.",
    "code": ""
  },
  {
    "path": "index.html",
    "id": "example-questions",
    "chapter": "Webexercises",
    "heading": "0.1 Example Questions",
    "text": "functions optimised used inline r code, can also use code chunks setting chunk option results = 'asis' using cat() display result widget.function loads package already computer? install.packageinstall.packageslibrarylibraries",
    "code": "\n# echo = FALSE, results = 'asis'\nopts <- c(\"install.package\", \n            \"install.packages\", \n            answer = \"library\", \n            \"libraries\")\n\nq1 <- mcq(opts)\n\ncat(\"What function loads a package that is already on your computer?\", q1)"
  },
  {
    "path": "index.html",
    "id": "fill-in-the-blanks-fitb",
    "chapter": "Webexercises",
    "heading": "0.1.1 Fill-In-The-Blanks (fitb())",
    "text": "Create fill---blank questions using fitb(), providing answer first argument.2 + 2 can also create questions dynamically, using variables R session.square root 16 : blanks case-sensitive; care case, use argument ignore_case = TRUE.letter D? want ignore differences whitespace use, use argument ignore_ws = TRUE (default) include spaces answer anywhere acceptable.load tidyverse package? can set one possible correct answer setting answers vector.Type vowel: can use regular expressions test answers complex rules.Type 3 letters: ",
    "code": ""
  },
  {
    "path": "index.html",
    "id": "multiple-choice-mcq",
    "chapter": "Webexercises",
    "heading": "0.1.2 Multiple Choice (mcq())",
    "text": "\"Never gonna give , never gonna: let goturn downrun awaylet \"\"bless rainsguess rainssense rain Africa\" -Toto",
    "code": ""
  },
  {
    "path": "index.html",
    "id": "true-or-false-torf",
    "chapter": "Webexercises",
    "heading": "0.1.3 True or False (torf())",
    "text": "True False? can permute values vector using sample(). TRUEFALSE",
    "code": ""
  },
  {
    "path": "index.html",
    "id": "longer-mcqs-longmcq",
    "chapter": "Webexercises",
    "heading": "0.1.4 Longer MCQs (longmcq())",
    "text": "answers long, sometimes drop-select box gets formatted oddly. can use longmcq() deal . Since answers long, probably best set options inside R chunk echo=FALSE.p-value?true 95% confidence interval mean?",
    "code": ""
  },
  {
    "path": "index.html",
    "id": "checked-sections",
    "chapter": "Webexercises",
    "heading": "0.2 Checked sections",
    "text": "Create sections class webex-check add button hides feedback pressed. Add class webex-box draw box around section (use styles).going learn lot: TRUEFALSE",
    "code": ""
  },
  {
    "path": "index.html",
    "id": "hidden-solutions-and-hints",
    "chapter": "Webexercises",
    "heading": "0.3 Hidden solutions and hints",
    "text": "can fence solution area hidden behind button using hide() solution unhide() , inline R code. Pass text want appear button hide() function.solution RMarkdown code chunk, instead using hide() unhide(), simply set webex.hide chunk option TRUE, set string wish display button.Recreate scatterplot , using built-cars dataset.See documentation plot() (?plot)",
    "code": "\nplot(cars$speed, cars$dist)"
  },
  {
    "objectID": "4A-Exercise.html#analyzing-the-regrowth-dataset",
    "href": "4A-Exercise.html#analyzing-the-regrowth-dataset",
    "title": "Exercise - Simple linear regression",
    "section": "Analyzing the “regrowth” dataset",
    "text": "Analyzing the “regrowth” dataset\n\n\n\n\n\n\nWarning\n\n\n\nImagine you have a garden with some fruit trees and you were thinking of adding some berry bushes between them. However, you don’t want them to suffer from malnutrition so you want to estimate the volume of root biomass as a function of the fruit biomass.\nCarry out the following tasks\n\nPerform a simple linear regression for the influence of fruit biomass on root biomass.\nVisualize the data and add the regression line to the plot.\n\nYou will need the following functions:\n\nlm()\nsummary()\nplot()\nabline()\n\n\nQuestion\nYou have performed a simple linear regression for the influence of fruit biomass on root biomass.\nWhich of the following statements are correct? (More than one are correct)\n\n Root biomass is not significantly affected by fruit biomass. Fruit biomass explains most of the variance (&gt;50%) in the root biomass. At a fruit biomass of 70, the model would predict root biomass of about 4.18 + 0.05*70. At a fruit biomass of 0, the model predicts a root biomass of about 4.18.\n\n\n\n\n\n\nClick here to see the solution\n\n### Solution\n\nRoot biomass is not significantly affected by fruit biomass. WRONG: Look at the p-value for the slope (2nd row in the regression table below Pr(&gt;|t|))\nFruit biomass explains most of the variance (&gt;50%) in the root biomass. CORRECT: The proportion of variance explained by the model is given by R2.\nAt a fruit biomass of 70, the model would predict root biomass of about \\(4.18 + 0.05*70\\). CORRECT: The linear equation for the model is: \\(y = a*x + b\\) that is \\(Root = slope*Fruit + intercept\\)\nAt a fruit biomass of 0, the model predicts a root biomass of about 4.18. CORRECT: This is the intercept (1st row in the regression table below Estimate)\n\nThis is the code that you need to interpret the results.\n\nlibrary(EcoData)\n# simple linear regression\nfit &lt;- lm(Root ~ Fruit, data = regrowth)\n\n# check summary for regression coefficient and p-value\nsummary(fit)\n## \n## Call:\n## lm(formula = Root ~ Fruit, data = regrowth)\n## \n## Residuals:\n##      Min       1Q   Median       3Q      Max \n## -1.25105 -0.69970 -0.01755  0.66982  1.63933 \n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(&gt;|t|)    \n## (Intercept) 4.184256   0.337987  12.380  6.6e-15 ***\n## Fruit       0.050444   0.005264   9.584  1.1e-11 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 0.8111 on 38 degrees of freedom\n## Multiple R-squared:  0.7073, Adjusted R-squared:  0.6996 \n## F-statistic: 91.84 on 1 and 38 DF,  p-value: 1.099e-11\n\n# plot root explained by fruit biomass\nplot(Root ~ Fruit, data = regrowth, \n     ylab = \"Root biomass in cubic meters\",\n     xlab = \"Fruit biomass in g\")\n\nabline(fit) # add regression line\nabline(v = 70, col = \"purple\") # add line at x value (here fruit biomass of 70g)\nabline(h = 4.184256 + 0.050444*70, col = \"brown\") # add line at y value according to x = 70 using the intercept and regression coefficient of x"
  },
  {
    "objectID": "4A-Exercise.html#analyzing-the-birdabundance-dataset",
    "href": "4A-Exercise.html#analyzing-the-birdabundance-dataset",
    "title": "Exercise - Simple linear regression",
    "section": "Analyzing the “birdabundance” dataset",
    "text": "Analyzing the “birdabundance” dataset\nThe dataset provides bird abundances in forest fragments with different characteristics in Australia. We want to look at the relationship of the variables “abundance”, “distance” and “grazing”.\n\n\n\n\n\n\nQuestions\n\n\n\nFirst, answer the following questions?:\n\nWhat is the most reasonable research question regarding these variables?\n\n\n How is grazing influenced by distance / abundance? How is distance influenced by grazing / abundance? How is abundance influenced by distance / grazing?\n\n\nWhat is the response variable?\n\n\n abundance distance grazing\n\n\nWhat is the predictor variable?\n\n\n either grazing or distance either abundance or distance either abundance or grazing\n\nThen, perform the following tasks:\n\nFit a simple linear regression relating the response variable to the categorical predictor (that is the one with five levels, make sure that it is indeed a factor using as.factor())\nApply an ANOVA to your model.\n\nYou may need the following functions:\n\nlm()\nsummary()\nanova()\n\nUse your results to chose the correct statement(s):\nYou have now fitted a simple linear regression with a categorical predictor and analyzed it. Which of the following statements are correct? (several statements are correct)\n\n The maximum likelihood estimate of bird abundance for grazing intensity 1 is 28.623. We can see in the regression table that the difference between grazing intensity 3 and 4 is significant. The non-significant p-value for grazing intensity 2 indicates that the data are compatible with the null hypothesis “H0: the bird abundance at grazing intensity 2 is on average 0.” The confidence interval for the estimate of the intercept is the smallest. The difference between grazing intensity 1 and 3 is significant. Grazing intensity in general has a highly significant effect (&lt; 0.001) on bird abundance.\n\n\n\n\n\nClick here to see the solution\n\n\nSolution\n\nThe maximum likelihood estimate of bird abundance for grazing intensity 1 is 28.623. CORRECT: When the predictor is a factor, the intercept equals the first factor level (by default, this follows an alphabetical order).\nWe can see in the regression table that the difference between grazing intensity 3 and 4 is significant. WRONG: Comparisons are always related to the intercept, i.e. to the first factor level. For comparisons among other factor levels we need post-hoc tests.\nThe non-significant p-value for grazing intensity 2 indicates that the data are compatible with the null hypothesis “H0: the bird abundance at grazing intensity 2 is on average 0.” WRONG: Comparisons are always related to the intercept, i.e. to the first factor level. Only the test for the intercept has H0: mean = 0.\n\nA reasonable research question is how abundance is influenced by distance and/or grazing. Here, the response variable is abundance, while the predictors are distance and/or grazing.\nThis is the code that you need to interpret the results.\n\n# change variable from integer to factor\nbirdabundance$GRAZE &lt;- as.factor(birdabundance$GRAZE) \nfit &lt;- lm(ABUND ~ GRAZE, data = birdabundance)\nsummary(fit)\n## \n## Call:\n## lm(formula = ABUND ~ GRAZE, data = birdabundance)\n## \n## Residuals:\n##      Min       1Q   Median       3Q      Max \n## -18.3867  -4.1159   0.0269   5.1484  16.4133 \n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(&gt;|t|)    \n## (Intercept)   28.623      2.086  13.723  &lt; 2e-16 ***\n## GRAZE2        -6.673      3.379  -1.975   0.0537 .  \n## GRAZE3        -7.336      2.850  -2.574   0.0130 *  \n## GRAZE4        -8.052      3.526  -2.284   0.0266 *  \n## GRAZE5       -22.331      2.950  -7.571 6.85e-10 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 7.52 on 51 degrees of freedom\n## Multiple R-squared:  0.5449, Adjusted R-squared:  0.5092 \n## F-statistic: 15.27 on 4 and 51 DF,  p-value: 2.846e-08\n\n# anova to check global effect of the factor grazing intensity\nanova(fit)\n## Analysis of Variance Table\n## \n## Response: ABUND\n##           Df Sum Sq Mean Sq F value    Pr(&gt;F)    \n## GRAZE      4 3453.7  863.42  15.267 2.846e-08 ***\n## Residuals 51 2884.2   56.55                      \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n# boxplot\nplot(ABUND ~ GRAZE, data = birdabundance)"
  },
  {
    "objectID": "4A-Exercise.html#model-validation-residual-checks",
    "href": "4A-Exercise.html#model-validation-residual-checks",
    "title": "Exercise - Simple linear regression",
    "section": "Model validation: Residual checks",
    "text": "Model validation: Residual checks\nNow, we will have a closer look at model diagnostics and residual checks in particular. Of course, we should have done this for all models above as well (we simply didn’t do this because of time restrictions). So remember that you always have to validate your model, if you want to be sure that your conclusions are correct.\nFor this exercise, you can prepare a dataset yourself called “dat” with the variables “x” and “y”. Simply copy the following code to generate the data:\n\nset.seed(234)\nx = rnorm(40, mean = 10, sd = 5)\ny = 10 - 2*x + 0.9 * x^2 + rnorm(40, mean=5, sd = 20)\ndat &lt;- data.frame(x, y)\nhead(dat)\n##           x          y\n## 1 13.303849 152.093910\n## 2 -0.264915   6.831275\n## 3  2.503970  45.207691\n## 4 17.356166 240.274237\n## 5 17.295693 240.917066\n## 6 10.700695 117.691234\n\nPerform the following tasks:\n\n\n\n\n\n\nWarning\n\n\n\n\nFit a simple linear regression.\nCheck the residuals.\nPerform another simple linear regression with a modified formula, if needed.\nCreate a scatter plot of the data and add a regression line for the first fit in black and one for the second fit in red. The second model cannot be plotted with the abline() function. Use the following code instead:\n\n\nlines(sort(x), predict(fit2, newdata = data.frame(x = sort(x))), col = \"red\")\n\nYou may also need the following functions:\n\nlm()\nsummary()\npar(mfrow = c(2, 2))\nplot()\nabline()\n\nUse your results to answer the following questions:\n\nWhat pattern do the residuals of the first regression model show when plotted against the fitted values?\nWhat do you have to do to improve your first regression model?\nIdentify the correct statement(s) about the residuals of the modified model.\n\n\n\n\n\nClick here to see the solution\n\n\nset.seed(234)\nx = rnorm(40, mean = 10, sd = 5)\ny = 10 - 2*x + 0.9 * x^2 + rnorm(40, mean=5, sd = 20)\ndat &lt;- data.frame(x, y)\n\n# simple linear regression\nfit &lt;- lm(y ~ x, dat)\n\n# check residuals\nop = par(mfrow=c(2,2))\nplot(fit) # residuals show a parabolic relationship (see first plot)  -&gt; to improve, fit a quadratic relationship\n\n\n\npar(op)\n\n# scatter plot\nplot(y ~ x, data = dat)\nabline(fit)\n\n\n\n\nsummary(fit) # significantly positively correlated, but this doesn't tell the full story because the residuals are not okay\n## \n## Call:\n## lm(formula = y ~ x, data = dat)\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -39.884 -22.208  -4.948  10.602 118.164 \n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(&gt;|t|)    \n## (Intercept)   -8.459     10.973  -0.771    0.446    \n## x             11.465      1.019  11.248 1.18e-13 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 32.11 on 38 degrees of freedom\n## Multiple R-squared:  0.769,  Adjusted R-squared:  0.763 \n## F-statistic: 126.5 on 1 and 38 DF,  p-value: 1.176e-13\n\n# improved regression model\nfit2 = lm(y ~ x + I(x^2), dat)\n\n# check residuals\nop = par(mfrow=c(2,2))\nplot(fit2) # no pattern in residuals anymore (first plot) -&gt; fit is fine\n\n\n\npar(op)\n\n# scatter plot\nplot(y ~ x, data = dat)\nabline(fit)\nlines(sort(x), predict(fit2, newdata = data.frame(x = sort(x))), col = \"red\")\n\n\n\n\n\nsummary(fit2) # significantly negatively correlated, trustworthy now, because residuals are sufficiently uniformly distributed (first plot in plot(fit2))\n## \n## Call:\n## lm(formula = y ~ x + I(x^2), data = dat)\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -33.174 -11.444   0.938  10.164  40.666 \n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(&gt;|t|)    \n## (Intercept) 17.87505    6.00812   2.975  0.00513 ** \n## x           -1.10100    1.27706  -0.862  0.39417    \n## I(x^2)       0.80752    0.07526  10.730 6.49e-13 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 16.05 on 37 degrees of freedom\n## Multiple R-squared:  0.9438, Adjusted R-squared:  0.9408 \n## F-statistic: 310.9 on 2 and 37 DF,  p-value: &lt; 2.2e-16"
  },
  {
    "objectID": "4B-Exercise.html#analyzing-the-mtcars-dataset",
    "href": "4B-Exercise.html#analyzing-the-mtcars-dataset",
    "title": "Exercise - Multiple Linear Regression",
    "section": "Analyzing the mtcars dataset",
    "text": "Analyzing the mtcars dataset\nImagine a start up company wants to rebuild a car with a nice retro look from the 70ies. The car should be modern though, meaning the fuel consumption should be as low as possible. They’ve discovered the mtcars dataset with all the necessary measurements and they’ve somehow heard about you and your R skills and asked you for help. And of course you promised to help, kind as you are.\nThe company wants you to find out which of the following characteristics affects the fuel consumption measured in miles per gallon (mpg). Lower values for mpg thus reflect a higher fuel consumption. The company wants you to include the following variables into your analysis:\n\nnumber of cylinders (cyl)\nweight (wt)\nhorsepower (hp)\nwhether the car is driven manually or with automatic (am)\n\nIn addition, Pawl, one of the founders of the company suggested that the effect of weight (wt) might be irrelevant for powerful cars (high hp values). You are thus asked to test for this interaction in your analysis as well.\n\n\n\n\n\n\nQuestion\n\n\n\nCarry out the following tasks:\n\nPerform a multiple linear regression (change class for cyl and am to factor)\nCheck the model residuals\nInterpret and plot all effects\n\nYou may need the following functions:\n\nas.factor()\nlm()\nsummary()\nanova()\nplot()\nallEffects()\n\nUse your results to answer the questions:\nWhich of the following statements are correct? (Several are correct).\n\n Cars with 6 cylinders do not differ significantly in their fuel consumption as compared to cars with 4 cylinders. Stronger cars (hp) use less fuel (mpg). Overall, heavier cars (wt) use significantly more fuel (their range is smaller; mpg)\n\nConcerning the interaction between weight (wt) and horsepower (hp), which of the following statements is correct?\n\n Pawl was wrong. There is a significant interaction between weight and horsepower, but the direction is opposite to what Pawl thought: The effect of weight is stronger for stronger cars. Pawl was wrong, the effect of weight is independent of horsepower. Pawl was right. The effect of weight is strong for weaker cars, but becomes indeed irrelevant for stronger cars.\n\n\n\n\n\nClick here to see the solution\n\nThis is the code that you need to interpret the results.\n\n# change am and cyl from numeric to factor\nmtcars$am &lt;- as.factor(mtcars$am)\nmtcars$cyl &lt;- as.factor(mtcars$cyl)\n\n# multiple linear regression and results:\n# (we need to scale (standardize) the predictors wt and hp, since we include their interaction)\ncarsfit &lt;- lm(mpg ~ am + cyl + scale(wt) * scale(hp), dat = mtcars)\n# weight is included as the first predictor in order to have\n# it as the grouping factor in the allEffects plot\n\nsummary(carsfit)\n## \n## Call:\n## lm(formula = mpg ~ am + cyl + scale(wt) * scale(hp), data = mtcars)\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -3.4121 -1.6789 -0.4446  1.3752  4.4338 \n## \n## Coefficients:\n##                     Estimate Std. Error t value Pr(&gt;|t|)    \n## (Intercept)          19.9064     1.5362  12.958 1.36e-12 ***\n## am1                   0.1898     1.4909   0.127 0.899740    \n## cyl6                 -1.2818     1.5291  -0.838 0.409813    \n## cyl8                 -1.3942     2.1563  -0.647 0.523803    \n## scale(wt)            -3.6248     0.9665  -3.750 0.000938 ***\n## scale(hp)            -1.8602     0.8881  -2.095 0.046503 *  \n## scale(wt):scale(hp)   1.5631     0.7027   2.224 0.035383 *  \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 2.246 on 25 degrees of freedom\n## Multiple R-squared:  0.888,  Adjusted R-squared:  0.8612 \n## F-statistic: 33.05 on 6 and 25 DF,  p-value: 1.021e-10\n# The first level of each factor is used as a reference, i.e. in this case a manual gear shift with 4 gears.\n# From the coefficient cyl6 we see that there is no significant difference in fuel consumption (= our response) between 4 gears (the reference) and 6 gears.\n# In contrast, the predictors weight (wt) and horsepower (hp) have a significant negative effect on the range (mpg), so that they both increase fuel consumption.\n\n# check residuals\nold.par = par(mfrow = c(2, 2))\nplot(carsfit)\n\n\n\npar(old.par)\n\n# plot effects\nplot(allEffects(carsfit))\n## Warning in Analyze.model(focal.predictors, mod, xlevels, default.levels, : the\n## predictors scale(wt), scale(hp) are one-column matrices that were converted to\n## vectors\n\n## Warning in Analyze.model(focal.predictors, mod, xlevels, default.levels, : the\n## predictors scale(wt), scale(hp) are one-column matrices that were converted to\n## vectors\n\n## Warning in Analyze.model(focal.predictors, mod, xlevels, default.levels, : the\n## predictors scale(wt), scale(hp) are one-column matrices that were converted to\n## vectors\n\n\n\n# We can see in the wt*hp plot, that for high values of hp wt has no effect on the response mpg. We conclude that Pawl was right.\n\n\n\n\n\n\n\n\n\nQuestion\n\n\n\n\nWhat is the meaning of “An effect is not significant”?\nIs an effect with three *** more significant / certain than an effect with one *?\n\n\n\n\n\nClick here to see the solution\n\n\nYou should NOT say that the effect is zero, or that the null hypothesis has been accepted. Official language is “there is no significant evidence for an effect(p = XXX)”. If we would like to assess what that means, some people do a post-hoc power analysis (which effect size could have been estimated), but better is typically just to discuss the confidence interval, i.e. look at the confidence interval and say: if there is an effect, we are relatively certain that it is smaller than X, given the confidence interval of XYZ.\nMany people view it that way, and some even write “highly significant” for *** . It is probably true that we should have a slightly higher confidence in a very small p-value, but strictly speaking, however, there is only significant, or not significant. Interpreting the p-value as a measure of certainty is a slight misinterpretation. Again, if we want to say how certain we are about the effect, it is better to look again at the confidence interval, i.e. the standard error and use this to discuss the precision of the estimate (small confidence interval / standard error = high precision / certainty)."
  },
  {
    "objectID": "4B-Exercise.html#model-selection-with-the-cement-dataset",
    "href": "4B-Exercise.html#model-selection-with-the-cement-dataset",
    "title": "Exercise - Multiple Linear Regression",
    "section": "Model-selection with the Cement dataset",
    "text": "Model-selection with the Cement dataset\nThe process of cement hardening involves exogenous chemical reactions and thus produces heat. The amount of heat produced by the cement depends on the mixture of its constituents. The Cement dataset includes heat measurements for different types of cement that consist of different relative amounts of calcium aluminate (X1), tricalcium silicate (X2), tetracalcium alumino ferrite (X3) and dicalcium silicate (X4). A cement producing company wants to optimize the composition of its product and wants to know, which of these compounds are mainly responsible for heat production.\n\n\n\n\n\n\nNote\n\n\n\nWe only do a model selection here for educational reasons. For your analysis, and if your goal is not a predictive model, think about the model structure before you do the analysis and then stick to it! See here the section about p-hacking (and also consider that AIC selection will/can remove confounders which will violate causality and can lead to spurious correlations!\n\n\n\n\n\n\n\n\nQuestions\n\n\n\nCarry out the following tasks:\n\nPerform a multiple linear regression including all predictor variables and all two-way interactions (remember the notation (var1 + var2 + var3)\\^2.\nPerform forward, backward, and global model selection and compare the results\nFit the model considered optimal by global model selection and compare it with the full model based on AIC (or AICc) and LRT.\n\nYou may need the following functions:\n\nlm()\nsummary()\nstepAIC()\noptions()\ndredge()\nAIC() or AICc() (for small datasets)\nanova()\n\nUse your results to answer the following questions:\n1. You tested 3 different model selection methods: forward stepwise AIC selection, backward stepwise AIC selection and global model selection. How many terms ( = intercept + predictor effects + interactions) did each of the reduced models include?\n\nForward selection \nBackward selection \nglobal model selection \n\n2. You compared the full model with the reduced model from global model selection based on AIC and LRT (using the anova() function). Which of the two models would you choose based on their AIC? And which would you choose based on the LRT?\n\nAIC The full modelI don’t know. Both models fit equally well.Also the full modelThe reduced model\nLRT The full modelI don’t know. Both models fit equally well.Also the full modelThe reduced model\n\n3. Here’s a quote from Wikipedia on the AIC: “When the sample size is small, there is a substantial probability that AIC will select models that have too many parameters, i.e. that AIC will overfit.” Check the sample size of the Cement dataset. How do you now interpret the AIC values for the full model as compared to the reduced model from global model selection? (Several are correct)\n\n The AIC for the full model is smaller. The full model thus fits better. I would not trust AIC model selection in this case, because the sample size is too small to fit the number of parameters necessary for the full model. Instead of using the AIC for model comparison, I would now prefer the AICc, which corrects for small sample sizes.\n\n\n\n\n\nClick here to see the solution\n\n\nSolution\nThis is the code that you need to obtain the results.\n\nlibrary(MuMIn)\nlibrary(MASS)\n\n# full model -&gt;  has 11 coefficients\nfull = lm(y ~ (X1 + X2 + X3 + X4)^2, data = Cement)\nsummary(full)\n\n# forward model selection\nms_forw = stepAIC(full, direction = \"forward\")\nsummary(ms_forw)\n# lists 11 coefficients (i.e. selects full model)\n\n# backward model selection\nms_back = stepAIC(full, direction = \"backward\")\nsummary(ms_back)\n# lists 10 coefficients\n\n# global model selection\noptions(na.action = \"na.fail\")\ndd = dredge(full)\nhead(dd)\n# The first row lists the best performing model: it includes only the intercept and effects for X1 and X2 (= 3 coefficients).\n\n# Fit the model considered optimal by global model selection and compare it with the full model based on AIC (or AICc) and LRT:\nopt = lm(y ~ X1 + X2, data = Cement)\nsummary(opt)\n\nAIC(opt,full) # full model is better according to AIC (lower AIC)\nanova(opt, full) # -&gt; LRT: no significant difference between the models\n\n# sample size in the Cement dataset:\nstr(Cement)  # or\nnrow(Cement)\n\n# If the sample size is low, a corrected version of the AIC is recommended to avoid overfitting:\nAICc(opt,full) # This is inf! -&gt; optimal model is better according to AICc"
  }
]